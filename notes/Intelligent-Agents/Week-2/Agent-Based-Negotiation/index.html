<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Conflict of Interest Conflict arises when agents have {different preferences or aims} In [[Introduction to Intelligent Agents#Multi-Agent System MAS|MAS]] conflicts arise when agents are {c1|self-interested} and the agents represent {c1|different stakeholders}"><meta property="og:title" content="Agent Based Negotiation"><meta property="og:description" content="Conflict of Interest Conflict arises when agents have {different preferences or aims} In [[Introduction to Intelligent Agents#Multi-Agent System MAS|MAS]] conflicts arise when agents are {c1|self-interested} and the agents represent {c1|different stakeholders}"><meta property="og:type" content="website"><meta property="og:image" content="https://ik1g19.github.io/UoS-Notes/icon.png"><meta property="og:url" content="https://ik1g19.github.io/UoS-Notes/notes/Intelligent-Agents/Week-2/Agent-Based-Negotiation/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Agent Based Negotiation"><meta name=twitter:description content="Conflict of Interest Conflict arises when agents have {different preferences or aims} In [[Introduction to Intelligent Agents#Multi-Agent System MAS|MAS]] conflicts arise when agents are {c1|self-interested} and the agents represent {c1|different stakeholders}"><meta name=twitter:image content="https://ik1g19.github.io/UoS-Notes/icon.png"><meta name=twitter:site content="_jzhao"><title>Agent Based Negotiation</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://ik1g19.github.io/UoS-Notes//icon.png><link href=https://ik1g19.github.io/UoS-Notes/styles.80333fa2099c0bee674efa435fde378c.min.css rel=stylesheet><link href=https://ik1g19.github.io/UoS-Notes/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://ik1g19.github.io/UoS-Notes/js/darkmode.fdbb50a651b073e7d85910aebde4469d.min.js></script>
<script src=https://ik1g19.github.io/UoS-Notes/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script async src=https://ik1g19.github.io/UoS-Notes/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://ik1g19.github.io/UoS-Notes/",fetchData=Promise.all([fetch("https://ik1g19.github.io/UoS-Notes/indices/linkIndex.4cd7744b37da745103d2e306cd2cd001.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://ik1g19.github.io/UoS-Notes/indices/contentIndex.a1e306a3e6a8cedcc8275a04564ca752.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://ik1g19.github.io/UoS-Notes",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://ik1g19.github.io/UoS-Notes",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/ik1g19.github.io\/UoS-Notes\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=ik1g19.github.io/UoS-Notes src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://ik1g19.github.io/UoS-Notes/>My UoS Notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Agent Based Negotiation</h1><p class=meta>Last updated
Apr 3, 2023
<a href=https://github.com/ik1g19/notes/Intelligent%20Agents/Week%202/Agent%20Based%20Negotiation.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#conflict-resolution>Conflict Resolution</a><ol><li></li><li><a href=#auctions-flashcard>Auctions #flashcard</a></li><li><a href=#voting-flashcard>Voting #flashcard</a></li><li><a href=#negotiation-flashcard>Negotiation #flashcard</a></li></ol></li></ol><ol><li><a href=#characterising-agent-negotiations>Characterising Agent Negotiations</a><ol><li><a href=#negotiation-environment-flashcard>Negotiation Environment #flashcard</a></li><li><a href=#agent-preferences-flashcard>Agent Preferences #flashcard</a></li><li><a href=#agent-negotiation-strategies-flashcard>Agent Negotiation Strategies #flashcard</a></li></ol></li><li><a href=#negotiation-protocols>Negotiation Protocols</a><ol><li><a href=#single-issue-negotiation>Single-Issue Negotiation</a></li><li><a href=#bilateral-negotiation-the-ultimatum-game-flashcard>Bilateral Negotiation: The Ultimatum Game #flashcard</a></li><li><a href=#alternating-offers-protocol-flashcard>Alternating Offers Protocol #flashcard</a></li><li><a href=#monotonic-concession-protocol-flashcard>Monotonic Concession Protocol #flashcard</a></li><li><a href=#divide-and-choose-flashcard>Divide and Choose #flashcard</a></li></ol></li><li><a href=#desirable-properties-of-a-negotiation-flashcard>Desirable Properties of a Negotiation #flashcard</a></li><li><a href=#agent-preferences>Agent Preferences</a><ol><li><a href=#there-are-two-types-of-utility-functions>There are Two types of Utility Functions</a></li></ol></li><li><a href=#price-negotiation-utility-space>Price Negotiation: Utility Space</a></li><li><a href=#time-pressure>Time Pressure</a><ol><li><a href=#deadlines-flashcard>Deadlines #flashcard</a></li><li><a href=#break-off-probability-flashcard>Break-Off Probability #flashcard</a></li><li><a href=#bargaining-costs-flashcard>Bargaining Costs #flashcard</a></li></ol></li><li><a href=#modelling-bargaining-costs>Modelling Bargaining Costs</a><ol><li><a href=#fixed-costs>Fixed Costs</a></li><li><a href=#discount-factors>Discount Factors</a></li></ol></li><li><a href=#multi-issue-negotiation>Multi-Issue Negotiation</a></li><li><a href=#pareto-efficient-agreements>Pareto-Efficient Agreements</a></li><li><a href=#desriable-properties>Desriable Properties</a></li><li><a href=#fairness>Fairness</a><ol><li><a href=#utilitarian-social-welfare>Utilitarian Social Welfare</a></li><li><a href=#egalitarian-social-welfare>Egalitarian Social Welfare</a></li><li><a href=#nash-bargaining-solution>Nash Bargaining Solution</a></li><li><a href=#envy-freeness>Envy-freeness</a></li></ol></li></ol><ol><li><ol><li></li></ol></li><li><a href=#heuristics>Heuristics</a><ol><li><a href=#concession-strategy>Concession Strategy</a></li><li><a href=#muti-issue-offer-producing-strategy>Muti-Issue Offer producing Strategy</a></li></ol></li><li><a href=#optimal-concession-strategy>Optimal Concession Strategy</a></li><li><a href=#offer-producing-strategy>Offer-producing Strategy</a></li><li><a href=#unknown-opponent-utility>Unknown Opponent Utility</a></li><li><a href=#preference-uncertainty-and-elicitation>Preference Uncertainty and Elicitation</a></li></ol></nav></details></aside><a href=#conflict-of-interest><h1 id=conflict-of-interest><span class=hanchor arialabel=Anchor># </span><strong>Conflict of Interest</strong></h1></a><p>Conflict arises when agents have {different preferences or aims}
In <a class="internal-link broken">MAS</a> conflicts arise when agents are {c1|self-interested} and the agents represent {c1|different stakeholders}</p><a href=#conflict-resolution><h2 id=conflict-resolution><span class=hanchor arialabel=Anchor># </span>Conflict Resolution</h2></a><p>Conflict resolution is possible when there is {a mutual benefit to reach an agreement}</p><a href=#approaches-for-conflict-resolution><h4 id=approaches-for-conflict-resolution><span class=hanchor arialabel=Anchor># </span>approaches for conflict resolution</h4></a><ul><li>Auctions</li><li>Voting</li><li>Negotiation</li></ul><a href=#auctions-flashcard><h3 id=auctions-flashcard><span class=hanchor arialabel=Anchor># </span>Auctions #flashcard</h3></a><p>Primarily used to allocate scarce resources or tasks</p><p>e.g.</p><ul><li>Items to buyers</li><li>Advertising space</li><li>Cloud computing</li><li>Stocks and shares</li></ul><a href=#characterised-by-flashcard><h4 id=characterised-by-flashcard><span class=hanchor arialabel=Anchor># </span>Characterised by #flashcard</h4></a><ul><li>Clearly defined protocol</li><li>Typically requires a trusted third party e.g. auctioneer</li><li>Often involves a continuous resource such as money</li><li>Exploits competition between agents - works better with more agents</li></ul><a href=#voting-flashcard><h3 id=voting-flashcard><span class=hanchor arialabel=Anchor># </span>Voting #flashcard</h3></a><p>Used for group based decisions (<strong>social chocice</strong>)</p><a href=#characterised-by-flashcard-1><h4 id=characterised-by-flashcard-1><span class=hanchor arialabel=Anchor># </span>characterised by #flashcard</h4></a><ul><li>A single decision from a (typically finite) number of options</li><li>Each agent can have different preferences for each option - given by a preference order (ordinal utility function)</li><li>Clearly defined protocol</li></ul><a href=#negotiation-flashcard><h3 id=negotiation-flashcard><span class=hanchor arialabel=Anchor># </span>Negotiation #flashcard</h3></a><p>Governed by a protocol which defines the <a href=/UoS-Notes#rules-of-encounter-flashcard rel=noopener class=internal-link data-src=/UoS-Notes>Rules of Encounter</a> between the agents</p><p>{More flexible} compared to other approaches</p><ul><li>Prtocol typically involves {exchanging offers, but can also include other information such as arguments (reasons why)}</li><li>Allows for {less structured} prtocols</li><li>Often <a href=/UoS-Notes#bilateral rel=noopener class=internal-link data-src=/UoS-Notes></a>, but some protocols support <a href=/UoS-Notes#multi-part-negotiation rel=noopener class=internal-link data-src=/UoS-Notes></a></li></ul><p>Enables more complex types of agreements (multi-issue negotiation)
Often decentralised (can involve mediator - agent mediated negotiation)</p><a href=#bilateral><h5 id=bilateral><span class=hanchor arialabel=Anchor># </span>Bilateral</h5></a><p>Between two agents</p><a href=#multi-party-negotiation><h5 id=multi-party-negotiation><span class=hanchor arialabel=Anchor># </span>Multi-Party Negotiation</h5></a><p>Between more than two agents</p><a href=#rules-of-encounter-flashcard><h4 id=rules-of-encounter-flashcard><span class=hanchor arialabel=Anchor># </span>rules of encounter #flashcard</h4></a><ul><li>Type of communication allowed</li><li>Type of proposals that are allowed</li><li>Who can make what proposal at what time</li></ul><a href=#negotiation><h1 id=negotiation><span class=hanchor arialabel=Anchor># </span><strong>Negotiation</strong></h1></a><a href=#characterising-agent-negotiations><h2 id=characterising-agent-negotiations><span class=hanchor arialabel=Anchor># </span>Characterising Agent Negotiations</h2></a><a href=#negotiation-environment-flashcard><h3 id=negotiation-environment-flashcard><span class=hanchor arialabel=Anchor># </span>Negotiation Environment #flashcard</h3></a><p>Set of possible outcomes/agreements</p><a href=#single-issue-negotiation-distributive-bargaining-flashcard><h4 id=single-issue-negotiation-distributive-bargaining-flashcard><span class=hanchor arialabel=Anchor># </span>Single-issue Negotiation (Distributive Bargaining) #flashcard</h4></a><ul><li>e.g. price</li><li>Win-lose</li><li>Competitive setting</li></ul><a href=#multi-issue-negotiation-integrative-bargaining-flashcard><h4 id=multi-issue-negotiation-integrative-bargaining-flashcard><span class=hanchor arialabel=Anchor># </span>Multi-issue Negotiation (Integrative Bargaining) #flashcard</h4></a><ul><li>Includes more issues</li><li>Allows for mutual benefit and cooperation</li></ul><a href=#agent-preferences-flashcard><h3 id=agent-preferences-flashcard><span class=hanchor arialabel=Anchor># </span>Agent Preferences #flashcard</h3></a><p>The preferences over all possible agreements (and disagreements), typically specified using utility functions</p><a href=#agent-negotiation-strategies-flashcard><h3 id=agent-negotiation-strategies-flashcard><span class=hanchor arialabel=Anchor># </span>Agent Negotiation Strategies #flashcard</h3></a><ul><li>Specifies the behaviour of the agents</li><li>Actions employed at each possible decision point, given the information available to the agent</li></ul><a href=#negotiation-protocols><h2 id=negotiation-protocols><span class=hanchor arialabel=Anchor># </span>Negotiation Protocols</h2></a><ul><li>Ultimatum Game</li><li>Alternating Offers</li><li>Monotonic Concession Protocol</li><li>Divide and Choose</li></ul><a href=#single-issue-negotiation><h3 id=single-issue-negotiation><span class=hanchor arialabel=Anchor># </span>Single-Issue Negotiation</h3></a><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221010165240.png width=600 alt=|600>
Overlap between sellers minimum price and buyers maximum price is the agreement space</p><a href=#bilateral-negotiation-the-ultimatum-game-flashcard><h3 id=bilateral-negotiation-the-ultimatum-game-flashcard><span class=hanchor arialabel=Anchor># </span>Bilateral Negotiation: The Ultimatum Game #flashcard</h3></a><ul><li>Agent 1 suggests a division</li><li>Agent 2 can only choose to accept or reject the proposed division</li><li>If agent 2 rejects, no-one receives anything</li><li>&lsquo;Take it or leave it&rsquo;</li></ul><a href=#advantagesdisadvantages-flashcard><h4 id=advantagesdisadvantages-flashcard><span class=hanchor arialabel=Anchor># </span>Advantages/Disadvantages #flashcard</h4></a><ul><li>Agent 1 has a clear advantage - the <strong>first-mover advantage</strong></li><li>Assumes the agreement space (the size of the pie) is known - the seller&rsquo;s reserve and buyer&rsquo;s willingness to pay are shared knowledge</li><li>No ability to explore the negotiation space</li></ul><a href=#alternating-offers-protocol-flashcard><h3 id=alternating-offers-protocol-flashcard><span class=hanchor arialabel=Anchor># </span>Alternating Offers Protocol #flashcard</h3></a><ul><li>Negotiation consists of a number of rounds</li><li>Agents exchange offers in an alternating fashion</li><li>First player starts with proposing an offer</li><li>Second player can either accept or reject and counter offer, or reject and break off negotiation</li><li>Negotiation ends after set number of rounds (deadline) or if either players breaks off negotiations
<img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221010173339.png width=400 alt=|400></li></ul><a href=#monotonic-concession-protocol-flashcard><h3 id=monotonic-concession-protocol-flashcard><span class=hanchor arialabel=Anchor># </span>Monotonic Concession Protocol #flashcard</h3></a><ul><li>Negotiations proceed in rounds</li><li>In each round, agents simultaneously propose offers (without seeing the other offer)</li><li>If both others &lsquo;match&rsquo; then one of them is chosen</li><li>Otherwise the negotiation proceeds to the next round</li><li>In the next round at least one of the agents need to concede</li><li>If neither of the agents concede, the negotiation ends without a deal</li></ul><a href=#divide-and-choose-flashcard><h3 id=divide-and-choose-flashcard><span class=hanchor arialabel=Anchor># </span>Divide and Choose #flashcard</h3></a><ul><li>Used when a continuous resource needs to be divided between multiple agents</li><li>Agent 1 divides the pie into 2 portions</li><li>Agent 2 chooses one of the portions
<img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221014124749.png width=400 alt=|400></li></ul><a href=#properties-flashcard><h4 id=properties-flashcard><span class=hanchor arialabel=Anchor># </span>Properties #flashcard</h4></a><ul><li>Only works for resource allocation problems</li><li>Also works for non-homogenous resources (when parts of the pie are more attractive)</li></ul><a href=#desirable-properties-of-a-negotiation-flashcard><h2 id=desirable-properties-of-a-negotiation-flashcard><span class=hanchor arialabel=Anchor># </span>Desirable Properties of a Negotiation #flashcard</h2></a><ul><li>A deal should be better than no deal for all agents (individual rationality)</li><li>There should be no pie left (Pareto efficiency)</li><li>The agreement should be fair</li></ul><a href=#agent-preferences><h2 id=agent-preferences><span class=hanchor arialabel=Anchor># </span>Agent Preferences</h2></a><p>An agents preferences over outcomes are modelled using a utility function $U(o)$, where $o\in O$ is the offer and $O$ is the set of possible offers</p><a href=#there-are-two-types-of-utility-functions><h3 id=there-are-two-types-of-utility-functions><span class=hanchor arialabel=Anchor># </span>There are Two types of Utility Functions</h3></a><a href=#ordinal-preferences-flashcard><h4 id=ordinal-preferences-flashcard><span class=hanchor arialabel=Anchor># </span>Ordinal Preferences #flashcard</h4></a><p>A preference order over outcomes is specified but there is no numerical utility
The agents specify what they prefer but now by how much</p><ul><li>e.g. $U(o_1) > U(o_2)$ means that $o_1$ is preferred over $o_2$</li></ul><a href=#cardinal-preferences><h4 id=cardinal-preferences><span class=hanchor arialabel=Anchor># </span>Cardinal preferences</h4></a><p>Each outcome has a numerical utility value</p><ul><li>e.g. $U(o_1) = 0.78, U(o_2) = 0.5$</li></ul><p>We can always infer ordinal preferences from cardinal ones</p><a href=#price-negotiation-utility-space><h2 id=price-negotiation-utility-space><span class=hanchor arialabel=Anchor># </span>Price Negotiation: Utility Space</h2></a><p>The utility space shows the utility of the two agents on respective axis for all possible outcomes
<a class="internal-link broken">Pasted image 20221014132155.png</a></p><a href=#time-pressure><h2 id=time-pressure><span class=hanchor arialabel=Anchor># </span>Time Pressure</h2></a><a href=#deadlines-flashcard><h3 id=deadlines-flashcard><span class=hanchor arialabel=Anchor># </span>Deadlines #flashcard</h3></a><ul><li>Imposed by protocol</li><li>Or determined by individual constraints (deadlines of agents can differ)</li></ul><a href=#break-off-probability-flashcard><h3 id=break-off-probability-flashcard><span class=hanchor arialabel=Anchor># </span>Break-Off Probability #flashcard</h3></a><ul><li>Imposed by protocol</li><li>Or agents can decide to break off negotiations themselves</li></ul><a href=#bargaining-costs-flashcard><h3 id=bargaining-costs-flashcard><span class=hanchor arialabel=Anchor># </span>Bargaining Costs #flashcard</h3></a><ul><li>Fixed bargaining costs per round</li><li>Discount factors</li></ul><a href=#modelling-bargaining-costs><h2 id=modelling-bargaining-costs><span class=hanchor arialabel=Anchor># </span>Modelling Bargaining Costs</h2></a><a href=#fixed-costs><h3 id=fixed-costs><span class=hanchor arialabel=Anchor># </span>Fixed Costs</h3></a><p>Let $c_i$ denote the costs for agent $i$, and $t$ be the time or bargaining round, then the utility at time $t$ is given by: $$U_i^t = U_i - t \cdot c_i$$</p><a href=#discount-factors><h3 id=discount-factors><span class=hanchor arialabel=Anchor># </span>Discount Factors</h3></a><p>Let $\delta_i &lt; 1$ be the discount factor of agent $i$, then the utility is given by: $$U_i^t = U_i \cdot \delta_i^t$$</p><a href=#multi-issue-negotiation><h2 id=multi-issue-negotiation><span class=hanchor arialabel=Anchor># </span>Multi-Issue Negotiation</h2></a><p>An offer/outcome $o$ is a vector consisting of a value $o_j$ for each issue $j$
Often a weighted additive utility function is assumed: $$U_i(o) = \sum_j w_{i,j} \cdot U_{i,j}(o_j)$$
Where $U_{i,j}(o_j)$ is the utility for issue $j$</p><a href=#pareto-efficient-agreements><h2 id=pareto-efficient-agreements><span class=hanchor arialabel=Anchor># </span>Pareto-Efficient Agreements</h2></a><p>An agreement is said to be Pareto efficient (Pareto optimal) if no further improvement is possible in the utility of one agent, without reducing the utility of the other agents</p><p><strong>Pareto Efficient Frontier</strong> - Set of all Pareto efficient agreements</p><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221014135629.png width=500 alt=|500></p><a href=#desriable-properties><h2 id=desriable-properties><span class=hanchor arialabel=Anchor># </span>Desriable Properties</h2></a><ul><li>Agreements should be individually rational - $U(o)>U(disagreement)$</li><li>Agreements should be Pareto efficient</li><li>Agreements should be fair</li></ul><a href=#fairness><h2 id=fairness><span class=hanchor arialabel=Anchor># </span>Fairness</h2></a><a href=#utilitarian-social-welfare><h3 id=utilitarian-social-welfare><span class=hanchor arialabel=Anchor># </span>Utilitarian Social Welfare</h3></a><p>Aka social welfare
Maximise the sum of utilities $$\max_{o\in O}U_1(o)+U_2(o)$$</p><a href=#egalitarian-social-welfare><h3 id=egalitarian-social-welfare><span class=hanchor arialabel=Anchor># </span>Egalitarian Social Welfare</h3></a><p>Maximise the minimum utility $$\max_{o\in O}\min_{i\in {1,2}}U_i(o)$$</p><a href=#nash-bargaining-solution><h3 id=nash-bargaining-solution><span class=hanchor arialabel=Anchor># </span>Nash Bargaining Solution</h3></a><p>Maximise the product of the utility of the agents (minus the disagreement pay off) $$\max_{o\in O}(U_1(o)-U_1(disagreement))\cdot (U_2(o)-U_2(disagreement))$$
The Nash Bargaining Solution is uniquely characterised by the following axioms or properties</p><ul><li><strong>Individual rationality</strong> - The solution always satisfies $U_1 \geq U_1(dis)$ and $U_2 \geq U_2(dis)$</li><li><strong>Pareto efficiency</strong></li><li><strong>Invariance to equivalent utility representations</strong> - The solution is insensitive to affine transformations</li><li><strong>Independence of irrelevant alternative (IIA)</strong> - Remove all the non-optimal agreements, and the optimal agreement remains the same</li><li><strong>Symmetry (SYM)</strong> - If the agents have the same preferences, then the solution gives them the same utilities</li></ul><a href=#envy-freeness><h3 id=envy-freeness><span class=hanchor arialabel=Anchor># </span>Envy-freeness</h3></a><p>No agent prefers the resources allocated to other agents
An agent is envious of another agent if it would prefer the allocation received by that agent
A solution is envy free if no agent prefers the allocation of another agent (no agent is envious)</p><p>Agents do not care about the utility of the other agent, only the share/allocation received by other agents</p><a href=#negotiation-strategies><h1 id=negotiation-strategies><span class=hanchor arialabel=Anchor># </span>Negotiation Strategies</h1></a><a href=#game-theoretic><h4 id=game-theoretic><span class=hanchor arialabel=Anchor># </span>Game Theoretic</h4></a><ul><li>Assumes rules of the game, preferences and beliefes of all players are common knowledge</li><li>Assumes full rationality on the part of all players</li><li>Preferences encoded in a (limited) set of player types</li><li>Closed systems, predetermined interaction, small sized games</li><li>Nash equilibrium</li></ul><a href=#heuristic-perspective><h4 id=heuristic-perspective><span class=hanchor arialabel=Anchor># </span>Heuristic Perspective</h4></a><ul><li>No common knowledge or perfect rationality assumptions needed</li><li>Agent behaviour is modeled directly</li><li>Suitable for open, dynamic environments</li><li>Space of possibilities is very large</li></ul><a href=#heuristics><h2 id=heuristics><span class=hanchor arialabel=Anchor># </span>Heuristics</h2></a><p>Heuristics used when there is unknowns about the opponent</p><a href=#concession-strategy><h3 id=concession-strategy><span class=hanchor arialabel=Anchor># </span>Concession Strategy</h3></a><p>What should be the target utility I think I should achieve at a particular point in the negotiation?
Well-known strategies include:</p><a href=#time-dependent-tactics><h4 id=time-dependent-tactics><span class=hanchor arialabel=Anchor># </span>Time-dependent tactics</h4></a><p>Only depend on time/current round of the negotiation and not on the opponent&rsquo;s action
Let $U_{max}$ and $U_{min}$ denote the agent&rsquo;s maximum and minimum acceptable utility
The target utility offered at time $t$ will be $$U_{target}(t)=U_{min}+(1-F(t))(U_{max}-U_{min})$$
Where $F(t)$ is a function between 0 and 1 and gives the fraction of the distance between best and worst offer, using a function such as $$F(t)=(\frac{\min(t,T_{max})}{T_{\max}})^\frac{1}{\beta}$$
Where $T_{\max}$ is the deadline and $\beta$ is a constant
$F(0)=0$ and $F(T_{\max})=1$</p><a href=#hard-headed-beta-rightarrow-0><h5 id=hard-headed-beta-rightarrow-0><span class=hanchor arialabel=Anchor># </span>Hard-Headed ($\beta \rightarrow 0$)</h5></a><ul><li>No concessions</li><li>Sticks to the initial offer throughout</li></ul><a href=#linear-time-dependent-concession-beta--1><h5 id=linear-time-dependent-concession-beta--1><span class=hanchor arialabel=Anchor># </span>Linear time-dependent concession ($\beta = 1$)</h5></a><ul><li>Concession is linear in the time remaining until the deadline</li></ul><a href=#boulware-beta--1><h5 id=boulware-beta--1><span class=hanchor arialabel=Anchor># </span>Boulware ($\beta &lt; 1$)</h5></a><ul><li>Concedes very slowly, initial offer is maintained until just before the deadline</li></ul><a href=#conceder-beta--1><h5 id=conceder-beta--1><span class=hanchor arialabel=Anchor># </span>Conceder ($\beta > 1$)</h5></a><ul><li>Concedes to the reservation value very quickly</li></ul><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221014153655.png width=400 alt=|400></p><a href=#tit-for-tat><h4 id=tit-for-tat><span class=hanchor arialabel=Anchor># </span>Tit-for-tat</h4></a><p>The agent detects the concession the opponent makes during the previous negotiation round, in terms of increase in its own utility function
The concession the agent makes in the next round is equal to (or less than) the concession made by the opponent in the previous round $$concession\leq U_{own}(o_{opponent}^t)-U_{own}(o_{opponent}^{t-1})$$
As long as the offer falls in the acceptable region</p><a href=#muti-issue-offer-producing-strategy><h3 id=muti-issue-offer-producing-strategy><span class=hanchor arialabel=Anchor># </span>Muti-Issue Offer producing Strategy</h3></a><p>Once a target utility is establised, what offer to produce at or around that target utility (to ensure Pareto efficiency)</p><a href=#optimal-concession-strategy><h2 id=optimal-concession-strategy><span class=hanchor arialabel=Anchor># </span>Optimal Concession Strategy</h2></a><p>If everything is known, then it is easy to compute a <strong>best response</strong></p><ul><li>i.e. the optimal concession given the utility and strategy of the opponent
If there is a lot of uncertainty about the opponents utility function and strategy, then machine learning techniques can be used to learn the opponent model</li><li>If the opponent does the same then game-theoretic approaches can be useful</li></ul><a href=#offer-producing-strategy><h2 id=offer-producing-strategy><span class=hanchor arialabel=Anchor># </span>Offer-producing Strategy</h2></a><p>In multi-issue negotiation, you need to generate a value for each issue
It is a good idea to ensure that the offer is always Pareto efficient
If the utility functions are known, it is possible to calculate the Pareto-efficient offer at a certain target utility level
<a class="internal-link broken">Pasted image 20221017132254.png</a></p><a href=#unknown-opponent-utility><h2 id=unknown-opponent-utility><span class=hanchor arialabel=Anchor># </span>Unknown Opponent Utility</h2></a><p>Typically the opponent utility is not known</p><ul><li>This is <strong>private information</strong>
It is possible to guess the opponent utiity function based on the offers received so far and the conessions observed</li><li>e.g. The opponent is likely to concede on their least preferred issues first, this can be used to guess the weight of that issue</li></ul><a href=#preference-uncertainty-and-elicitation><h2 id=preference-uncertainty-and-elicitation><span class=hanchor arialabel=Anchor># </span>Preference Uncertainty and Elicitation</h2></a><p>In many cases even the agents own utility function is not fully known by itself
The utility function is obtained through a process called <strong>preference elicitation</strong></p><ul><li>Has associated &lsquo;cognitive costs&rsquo;</li><li>Trade-off between minimizing cognitive cost and maximising utility</li></ul><a href=#tags><h1 id=tags><span class=hanchor arialabel=Anchor># </span>Tags</h1></a><p>FILE TAGS intelligentAgents</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://ik1g19.github.io/UoS-Notes/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Isaac Klugman using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://ik1g19.github.io/UoS-Notes/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>GitHub</a></li></ul></footer></div></div></body></html>