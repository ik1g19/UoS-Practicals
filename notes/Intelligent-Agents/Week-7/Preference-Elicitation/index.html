<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Preference Orderings For finite outcome set $O$ $y\succeq z$ means $y$ is weakly prefered to $z$ $y\succ z$ means $y$ is strictly prefered to $z$"><meta property="og:title" content="Preference Elicitation"><meta property="og:description" content="Preference Orderings For finite outcome set $O$ $y\succeq z$ means $y$ is weakly prefered to $z$ $y\succ z$ means $y$ is strictly prefered to $z$"><meta property="og:type" content="website"><meta property="og:image" content="https://ik1g19.github.io/UoS-Notes/icon.png"><meta property="og:url" content="https://ik1g19.github.io/UoS-Notes/notes/Intelligent-Agents/Week-7/Preference-Elicitation/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Preference Elicitation"><meta name=twitter:description content="Preference Orderings For finite outcome set $O$ $y\succeq z$ means $y$ is weakly prefered to $z$ $y\succ z$ means $y$ is strictly prefered to $z$"><meta name=twitter:image content="https://ik1g19.github.io/UoS-Notes/icon.png"><meta name=twitter:site content="_jzhao"><title>Preference Elicitation</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://ik1g19.github.io/UoS-Notes//icon.png><link href=https://ik1g19.github.io/UoS-Notes/styles.80333fa2099c0bee674efa435fde378c.min.css rel=stylesheet><link href=https://ik1g19.github.io/UoS-Notes/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://ik1g19.github.io/UoS-Notes/js/darkmode.fdbb50a651b073e7d85910aebde4469d.min.js></script>
<script src=https://ik1g19.github.io/UoS-Notes/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script async src=https://ik1g19.github.io/UoS-Notes/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://ik1g19.github.io/UoS-Notes/",fetchData=Promise.all([fetch("https://ik1g19.github.io/UoS-Notes/indices/linkIndex.4cd7744b37da745103d2e306cd2cd001.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://ik1g19.github.io/UoS-Notes/indices/contentIndex.a1e306a3e6a8cedcc8275a04564ca752.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://ik1g19.github.io/UoS-Notes",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://ik1g19.github.io/UoS-Notes",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/ik1g19.github.io\/UoS-Notes\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=ik1g19.github.io/UoS-Notes src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://ik1g19.github.io/UoS-Notes/>My UoS Notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Preference Elicitation</h1><p class=meta>Last updated
Apr 3, 2023
<a href=https://github.com/ik1g19/notes/Intelligent%20Agents/Week%207/Preference%20Elicitation.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><ol><li><a href=#conditions>Conditions</a></li><li><a href=#equivalence-classes>Equivalence Classes</a></li></ol></li></ol><ol><li><a href=#pairwise-queries>Pairwise Queries</a></li><li><a href=#interviews>Interviews</a></li><li><a href=#pairwise-queries-vs-interviews>Pairwise Queries vs Interviews</a></li><li><a href=#elicitation-schemestrategyplan>Elicitation Scheme/Strategy/Plan</a></li><li><a href=#probabilistic-preferences>Probabilistic Preferences</a></li></ol><ol><li><a href=#multi-criteria-decision-analysis-mcda>Multi-Criteria Decision Analysis (MCDA)</a></li><li><a href=#multi-attribute-additive-value-functions-maavf>Multi-Attribute Additive Value Functions (MAAVF)</a></li><li><a href=#weighted-additive-utility-value-functions>Weighted Additive Utility Value Functions</a></li><li><a href=#ordinal-regression>Ordinal Regression</a></li></ol><ol><li><a href=#principle-of-the-uta-method>Principle of the UTA Method</a><ol><li><a href=#assumptions>Assumptions</a></li><li><a href=#reference-outcomes>Reference Outcomes</a></li><li><a href=#piece-wise-linear-marginal-value-functions>Piece-Wise Linear Marginal Value Functions</a></li><li><a href=#constraints-for-a-compatible-value-function>Constraints for a Compatible Value Function</a></li><li><a href=#solution-or-no-solution>Solution or No Solution</a></li></ol></li></ol><ol><li><a href=#limitations-of-uta>Limitations of UTA</a></li><li><a href=#utagms>$UTA^{GMS}$</a></li><li><a href=#assumptions-1>Assumptions</a></li><li><a href=#necessary-and-possible-weak-preference-relations>Necessary and Possible weak Preference Relations</a></li><li><a href=#from-partial-preference-ordering>From Partial Preference Ordering</a></li><li><a href=#constraints-for-a-compatible-value-function-1>Constraints for a Compatible Value Function</a></li><li><a href=#turning-ear-into-a-linear-program>Turning $E^{A^R}$ into a Linear Program</a></li><li><a href=#computation-of-succeqn-and-succeqp>Computation of $\succeq^N$ and $\succeq^P$</a></li><li><a href=#ordinal-regression-constraints-eab>Ordinal Regression Constraints $E(a,b)$</a></li><li><a href=#linear-programs-to-compute-succeqn>Linear Programs to compute $\succeq^N$</a></li><li><a href=#linear-program-to-compute-succeqp>Linear Program to compute $\succeq^p$</a></li><li><a href=#summary-of-utagms>Summary of $UTA^{GMS}$</a></li></ol></nav></details></aside><a href=#preference-orderings><h1 id=preference-orderings><span class=hanchor arialabel=Anchor># </span>Preference Orderings</h1></a><p>For finite outcome set $O$
$y\succeq z$ means $y$ is weakly prefered to $z$
$y\succ z$ means $y$ is strictly prefered to $z$</p><ul><li>It is true iff $y\succeq z$ and $z\cancel{\succeq}y$
$y\sim z$ means indifferent between $y$ and $z$</li><li>It is true iff $y\succeq z$ and $z \succeq y$</li></ul><a href=#conditions><h3 id=conditions><span class=hanchor arialabel=Anchor># </span>Conditions</h3></a><a href=#reflexive><h4 id=reflexive><span class=hanchor arialabel=Anchor># </span>Reflexive</h4></a><p>$x\succeq x$ for all $x\in O$</p><a href=#transitive><h4 id=transitive><span class=hanchor arialabel=Anchor># </span>transitive</h4></a><p>For all $x,y,z\in O$, if $x\succeq y$ and $y\succeq z$ then $x\succeq z$</p><a href=#totalconnected><h4 id=totalconnected><span class=hanchor arialabel=Anchor># </span>total/connected</h4></a><p>$y\succeq z$ or $z\succeq y$ for all $y,z\in O$</p><p>$\succeq$ that satisfies the above conditions is called a total preorder</p><a href=#equivalence-classes><h3 id=equivalence-classes><span class=hanchor arialabel=Anchor># </span>Equivalence Classes</h3></a><p>A <strong>tie</strong> or <strong>equivalence class</strong> consists of outcomes that we are indifferent between</p><a href=#preference-uncertainty><h1 id=preference-uncertainty><span class=hanchor arialabel=Anchor># </span>Preference Uncertainty</h1></a><p>Learning our preferences is costly
Often there are too many outcomes and ranking them is too costly
Instead we partially learn our preferences</p><a href=#preference-elicitation><h1 id=preference-elicitation><span class=hanchor arialabel=Anchor># </span>Preference Elicitation</h1></a><p>We start with partial (or no) information about our preferences
We learn more about preferences by making queries</p><p><strong>Pairwise Queries</strong> - Compare two given outcomes
<strong>Interviews</strong> - Learn as much as possible about the value of an outcome</p><a href=#pairwise-queries><h2 id=pairwise-queries><span class=hanchor arialabel=Anchor># </span>Pairwise Queries</h2></a><p>Two given outcomes $x$ and $y$ are compared against each other and the result is one of the following</p><ul><li>$x \succ y$</li><li>$y\succ x$</li><li>$x\sim y$</li></ul><a href=#interviews><h2 id=interviews><span class=hanchor arialabel=Anchor># </span>Interviews</h2></a><p>A given outcome $x$ is thoroughly investigated
After interviewing $\ell$ outcomes, we fully learn our preference ordering over these $\ell$ outcomes</p><a href=#pairwise-queries-vs-interviews><h2 id=pairwise-queries-vs-interviews><span class=hanchor arialabel=Anchor># </span>Pairwise Queries vs Interviews</h2></a><p>Interviews are generally assumed to be a lot more costly than pairwise comparisons</p><ul><li>Pairwise comparisons are useful if the two outcomes are sufficiently distinct</li><li>Interviews are needed when the outcomes are similar and more information is needed to rank them</li></ul><a href=#elicitation-schemestrategyplan><h2 id=elicitation-schemestrategyplan><span class=hanchor arialabel=Anchor># </span>Elicitation Scheme/Strategy/Plan</h2></a><p>An elicitation plan describes when and what to ask
The plan may depend on the result of the previous queries</p><a href=#probabilistic-preferences><h2 id=probabilistic-preferences><span class=hanchor arialabel=Anchor># </span>Probabilistic Preferences</h2></a><p>Not all query results are deterministic</p><a href=#multi-criteria-ranking-using-multi-attribute-additive-functions><h1 id=multi-criteria-ranking-using-multi-attribute-additive-functions><span class=hanchor arialabel=Anchor># </span>Multi Criteria Ranking using Multi-Attribute Additive Functions</h1></a><a href=#multi-criteria-decision-analysis-mcda><h2 id=multi-criteria-decision-analysis-mcda><span class=hanchor arialabel=Anchor># </span>Multi-Criteria Decision Analysis (MCDA)</h2></a><p>A finite set of outcomes or alternatives $O={a,b,c,d,&mldr;}$ is evaluated on a family of $n$ criteria or issues where $g_i(o)\in \mathbb{R}$ is the evaluation of issue $i$ in outcome $o$, for all $i\in{1,&mldr;,n}$ and $o\in O$</p><p>The greater $g_i(o)$,$o\in O$, the better outcome $o$ on issue $i$</p><ul><li>$a$ is at least as good as $b$ with respect to issue $i$ where $g_i(a)\geq g_i(b)$</li></ul><a href=#multi-attribute-additive-value-functions-maavf><h2 id=multi-attribute-additive-value-functions-maavf><span class=hanchor arialabel=Anchor># </span>Multi-Attribute Additive Value Functions (MAAVF)</h2></a><p>The agents utility is in the form of an additive value function, such that $$U(o)=\sum\limits_{i=1}^{n}u_i(g_i(o))$$
Where $u_i : \mathbb{R}\rightarrow\mathbb{R}$ is a non-decreasing marginal value function for issue $i,i\in{1,&mldr;,n}$
Sometimes $u_i(g_i(o_i))$ will just be referred to as $u_i(o_i)$</p><p>Value functions are increasing with respect to preference ordering</p><ul><li>$a\succ b \Longleftrightarrow U(a)>U(b)$</li><li>$a\sim b \Longleftrightarrow U(a) = U(b)$</li></ul><a href=#weighted-additive-utility-value-functions><h2 id=weighted-additive-utility-value-functions><span class=hanchor arialabel=Anchor># </span>Weighted Additive Utility Value Functions</h2></a><p>Weighted additive value/utility functions are a particular case of the multi-attribute value function where $u_i=w_i\cdot g_i(o)$</p><a href=#ordinal-regression><h2 id=ordinal-regression><span class=hanchor arialabel=Anchor># </span>Ordinal Regression</h2></a><p>The agent has some partial information about their preference ordering
$u_i$&rsquo;s are unknown
Usually assumed that $g_i$&rsquo;s are known</p><p>Goal is to find the agent&rsquo;s preference ordering
Use the partial preference ordering and a set of parameters (i.e. $u_i$&rsquo;s) that respect the partial information found to generate a complete preference ordering</p><p><strong>UTA</strong> - The first and well-known additive <a class="internal-link broken">Ordinal Regression</a> method</p><ul><li>Assumes that the agent knows their complete preference ordering over a set of reference outcomes (or alternatives) $O^R\subseteq O$</li><li>Among many compatible additive value functions that are consistent with the partial preference information, only one is selected and used to generate a complete preference ordering</li><li>Assumes that marginal value functions $u_i$&rsquo;s are piecewise-linear</li></ul><p><strong>UTA$^{GMS}$</strong> - The first method of robust additive <a class="internal-link broken">Ordinal Regression</a></p><ul><li>The agents ranking of reference outcomes does not need to be complete</li><li>Takes into consideration the whole set of compatible additive value functions</li><li>Marginal value functions are general non-decreasing functions</li></ul><a href=#ordinal-regression-via-linear-programming><h1 id=ordinal-regression-via-linear-programming><span class=hanchor arialabel=Anchor># </span>Ordinal Regression via Linear Programming</h1></a><a href=#principle-of-the-uta-method><h2 id=principle-of-the-uta-method><span class=hanchor arialabel=Anchor># </span>Principle of the UTA Method</h2></a><a href=#assumptions><h3 id=assumptions><span class=hanchor arialabel=Anchor># </span>Assumptions</h3></a><p>Agent knows their complete preference ordering over a set of reference outcomes $O^R \subseteq O$
The range of $g_i$ is $[\alpha_i,\beta_i]$,$\alpha_i&lt;\beta_i$</p><ul><li>Finite bound</li><li>$\alpha_i$ is the worst finite evaluation for issue $i$</li><li>$\beta_i$ is the best finite evaluation for issue $i$
$u_i$&rsquo;s are piecewise-linear, so that the interval $[\alpha_i,\beta_i]$ is divided into $\gamma_i\leq 1$ equal sub-intervals
$u_i$&rsquo;s are normalised to bound $U(o)$ in the interval $[0,1]$</li><li>$u_i(\alpha_i)=0$,$\forall i \in {1,&mldr;,n}$</li><li>$\sum\limits_{i=1}^{n}u_i(\beta_i)=1$</li></ul><a href=#reference-outcomes><h3 id=reference-outcomes><span class=hanchor arialabel=Anchor># </span>Reference Outcomes</h3></a><p>A value function $U$ is compatible if and only if for each $c,d\in O^R$</p><ul><li>$U(c)\geq U(d)\Longleftrightarrow c\succeq d$</li><li>$U(c)>U(d)\Longleftrightarrow c\succ d$</li><li>$U(c)=U(d)\Longleftrightarrow c\sim d$</li></ul><a href=#piece-wise-linear-marginal-value-functions><h3 id=piece-wise-linear-marginal-value-functions><span class=hanchor arialabel=Anchor># </span>Piece-Wise Linear Marginal Value Functions</h3></a><p>For each $i\in {1,&mldr;,n}$, the range of $g_i$ is $[\alpha_i,\beta_i]$,$\alpha_i&lt;\beta_i$
This interval is divided into $\gamma_i\geq 1$ equal sub-intervals $$[x_i^0,x_i^1],[x_i^1,x_i^2],&mldr;,[x_i^{\gamma_i-1},x_i^{\gamma_i}]$$ where $x_i^j=\alpha_i+\frac{j}{\gamma_i}(\beta_i-\alpha_i),j=1\text{&mldr;}\gamma_i$</p><p>The marginal value of an outcome $o\in O$ on issue $i$ is obtained by linear interpolation $$u_i(o_i)=u_i(x_i^j)+\frac{o_i-x_i^j}{x_i^{j+1}-x_i^j}(u_i(x_i^{j+1})-u_i(x_i^j))$$ $$o_i\in[x_i^j,x_i^{j+1}]$$The piecewise-linear additive model is completely defined by the marginal values at the breakpoints
i.e. $u_i(x_i^0)=u_i(\alpha_i),u_i(x_i^1),\text{&mldr;},u_i(x_i^{\gamma_i})=u_i(\beta_i)$</p><a href=#constraints-for-a-compatible-value-function><h3 id=constraints-for-a-compatible-value-function><span class=hanchor arialabel=Anchor># </span>Constraints for a Compatible Value Function</h3></a><p>A value function $U(o)=\sum\limits_{i=1}^n u_i(o_i)$ is compatible if it satisfies the following set of constraints
$$\begin{array}{l}
U(c)>U(d)\Longleftrightarrow c\succ d\\ U(c)=U(d)\Longleftrightarrow c\sim d\\ \end{array}
\biggr}\forall c,d\in O^R$$
$$u_i(x_i^{j+1})-u_i(x_i^j)\geq 0,i=1,&mldr;,n,j=1,&mldr;,\gamma_i-1$$
$$\begin{array} uu_i(\alpha_i)=0 & i=1,&mldr;,n\\end{array}$$
$$\sum\limits_{i=1}^nu_i(\beta_i)=1$$</p><a href=#example><h4 id=example><span class=hanchor arialabel=Anchor># </span>Example</h4></a><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221125175642.png width=450 alt=|450>
<img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221125180245.png width=450 alt=|450></p><a href=#solution-or-no-solution><h3 id=solution-or-no-solution><span class=hanchor arialabel=Anchor># </span>Solution or No Solution</h3></a><p>If the optimal value of the objective function is equal to zero (i.e. if all $\sigma^+(c)&rsquo;s$ and $\sigma^-(c)&rsquo;s$ are set to zero), then there exists at least one value function $U(o)=\sum\limits_{i=1}^{n}u_i(\sigma_i)$ compatible with the preference ordering on $O^R$</p><p>If the optimal value of the objective function is greater than zero, then there is no compatible value function
in this case you can consider</p><ul><li>Increasing $\gamma_i$ for one or several marginal values</li><li>Revising the preference ordering on $O^R$</li></ul><a href=#robust-ordinal-regression-utagms><h1 id=robust-ordinal-regression-utagms><span class=hanchor arialabel=Anchor># </span>Robust Ordinal Regression ($UTA^{GMS}$)</h1></a><a href=#limitations-of-uta><h2 id=limitations-of-uta><span class=hanchor arialabel=Anchor># </span>Limitations of UTA</h2></a><p>If the linear program is feasible, then the choice of a compatible value function is arbitrary
Marginal value functions are limited to piecewise linear function
Complete preference ordering on reference outcomes is needed</p><a href=#utagms><h2 id=utagms><span class=hanchor arialabel=Anchor># </span>$UTA^{GMS}$</h2></a><p>Takes into consideration the whole set of compatible additive value functions
Marginal value functions are general non-decreasing functions
The agent&rsquo;s ranking of reference outcomes does not need to be complete</p><a href=#assumptions-1><h2 id=assumptions-1><span class=hanchor arialabel=Anchor># </span>Assumptions</h2></a><p>Agent knows their partial preference ordering over a set of reference outcomes $O^R\subset O,|O^R|=m$
Same assumptions as in UTA</p><a href=#necessary-and-possible-weak-preference-relations><h2 id=necessary-and-possible-weak-preference-relations><span class=hanchor arialabel=Anchor># </span>Necessary and Possible weak Preference Relations</h2></a><p>Necessary weak preference relation $\succeq^N$ where $\alpha\succeq^N b\Leftrightarrow U(a)\geq U(b)$ for all compatible value functions
Possible weak preference relation $\succeq^p$ where $\alpha\succeq^p b\Leftrightarrow U(a)\geq U(b)$ for all compatible value function</p><a href=#from-partial-preference-ordering><h2 id=from-partial-preference-ordering><span class=hanchor arialabel=Anchor># </span>From Partial Preference Ordering</h2></a><p>For any $a,b\in O^R$</p><ul><li>If $\alpha\succeq b\Rightarrow a\succeq^N b$</li><li>If $\alpha\succ b\Rightarrow \neg(b \succeq^p a)$</li></ul><a href=#constraints-for-a-compatible-value-function-1><h2 id=constraints-for-a-compatible-value-function-1><span class=hanchor arialabel=Anchor># </span>Constraints for a Compatible Value Function</h2></a><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221205153020.png width=450 alt=|450></p><a href=#turning-ear-into-a-linear-program><h2 id=turning-ear-into-a-linear-program><span class=hanchor arialabel=Anchor># </span>Turning $E^{A^R}$ into a Linear Program</h2></a><p>Use the same trick as used for UTA, we can rewrite the first set of constraints as $$U(c)\geq U(d)+\epsilon \Leftrightarrow c \succ d$$ for an aribitrarily small $\epsilon$</p><a href=#computation-of-succeqn-and-succeqp><h2 id=computation-of-succeqn-and-succeqp><span class=hanchor arialabel=Anchor># </span>Computation of $\succeq^N$ and $\succeq^P$</h2></a><p>For all pairs of outcomes $(a,b)\in O \times O$, let $\pi_i$ be a permutation of the indices of outcomes from set $O^R\cup {a,b}$ that reorders them according to increasing evaluation on attribute $i$ i.e. $$g_i(a_{\pi_i(1)})\leq g_i(a_{\pi_i(2)})\leq&mldr;\leq g_i(a_{\pi_i(w)})$$ where $w=|O^R\cup {a,b}|$</p><p>Fix the characteristic points of $u_i,i=1,&mldr;,n$ in $g_i^0=\alpha_i$, $g_i^j=g_i(a_{\pi_i(j)})$ for $j=1,&mldr;,w$, $g_i^{w+1}=\beta_i$</p><a href=#ordinal-regression-constraints-eab><h2 id=ordinal-regression-constraints-eab><span class=hanchor arialabel=Anchor># </span>Ordinal Regression Constraints $E(a,b)$</h2></a><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221205161107.png width=450 alt=|450></p><a href=#linear-programs-to-compute-succeqn><h2 id=linear-programs-to-compute-succeqn><span class=hanchor arialabel=Anchor># </span>Linear Programs to compute $\succeq^N$</h2></a><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221205161229.png width=450 alt=|450></p><a href=#linear-program-to-compute-succeqp><h2 id=linear-program-to-compute-succeqp><span class=hanchor arialabel=Anchor># </span>Linear Program to compute $\succeq^p$</h2></a><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221205161328.png width=450 alt=|450></p><a href=#summary-of-utagms><h2 id=summary-of-utagms><span class=hanchor arialabel=Anchor># </span>Summary of $UTA^{GMS}$</h2></a><p><img src=https://ik1g19.github.io/UoS-Notes//notes/Intelligent%20Agents/Images/Pasted%20image%2020221205161438.png width=450 alt=|450></p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://ik1g19.github.io/UoS-Notes/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Isaac Klugman using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://ik1g19.github.io/UoS-Notes/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>GitHub</a></li></ul></footer></div></div></body></html>