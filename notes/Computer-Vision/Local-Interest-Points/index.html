<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="What makes a good Interest Point in an Image?  Invariance to brightness change  Local changes as well as global ones   Sufficient texture variation in the local neighbourhood Invariance to position between the angle/position of the scene to the camera  Finding Interest Points Different types of interest points to choose from Blob Detection - Difference-of-Gaussian Extrema  Corner Detection - Harris and Stephens  Harris and Stephens Corner Detector Basic Idea  Shifting that window by a small amount in any direction should give a large change in intensity Search for corners by looking through a small window  &ldquo;Flat&rdquo; Region No change in all directions &ldquo;Edge&rdquo; Region No change along the edge direction &ldquo;Corner&rdquo; Region Significant change in all directions Mathematics Weighted average change in intensity between a window and a shifted version by $(\Delta x,\Delta y)$ of that window"><meta property="og:title" content="Local Interest Points"><meta property="og:description" content="What makes a good Interest Point in an Image?  Invariance to brightness change  Local changes as well as global ones   Sufficient texture variation in the local neighbourhood Invariance to position between the angle/position of the scene to the camera  Finding Interest Points Different types of interest points to choose from Blob Detection - Difference-of-Gaussian Extrema  Corner Detection - Harris and Stephens  Harris and Stephens Corner Detector Basic Idea  Shifting that window by a small amount in any direction should give a large change in intensity Search for corners by looking through a small window  &ldquo;Flat&rdquo; Region No change in all directions &ldquo;Edge&rdquo; Region No change along the edge direction &ldquo;Corner&rdquo; Region Significant change in all directions Mathematics Weighted average change in intensity between a window and a shifted version by $(\Delta x,\Delta y)$ of that window"><meta property="og:type" content="website"><meta property="og:image" content="https://ik1g19.github.io/UoS-Notes/icon.png"><meta property="og:url" content="https://ik1g19.github.io/UoS-Notes/notes/Computer-Vision/Local-Interest-Points/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content="Local Interest Points"><meta name=twitter:description content="What makes a good Interest Point in an Image?  Invariance to brightness change  Local changes as well as global ones   Sufficient texture variation in the local neighbourhood Invariance to position between the angle/position of the scene to the camera  Finding Interest Points Different types of interest points to choose from Blob Detection - Difference-of-Gaussian Extrema  Corner Detection - Harris and Stephens  Harris and Stephens Corner Detector Basic Idea  Shifting that window by a small amount in any direction should give a large change in intensity Search for corners by looking through a small window  &ldquo;Flat&rdquo; Region No change in all directions &ldquo;Edge&rdquo; Region No change along the edge direction &ldquo;Corner&rdquo; Region Significant change in all directions Mathematics Weighted average change in intensity between a window and a shifted version by $(\Delta x,\Delta y)$ of that window"><meta name=twitter:image content="https://ik1g19.github.io/UoS-Notes/icon.png"><meta name=twitter:site content="_jzhao"><title>Local Interest Points</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://ik1g19.github.io/UoS-Notes//icon.png><link href=https://ik1g19.github.io/UoS-Notes/styles.80333fa2099c0bee674efa435fde378c.min.css rel=stylesheet><link href=https://ik1g19.github.io/UoS-Notes/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://ik1g19.github.io/UoS-Notes/js/darkmode.fdbb50a651b073e7d85910aebde4469d.min.js></script>
<script src=https://ik1g19.github.io/UoS-Notes/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script async src=https://ik1g19.github.io/UoS-Notes/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://ik1g19.github.io/UoS-Notes/",fetchData=Promise.all([fetch("https://ik1g19.github.io/UoS-Notes/indices/linkIndex.4cd7744b37da745103d2e306cd2cd001.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://ik1g19.github.io/UoS-Notes/indices/contentIndex.a1e306a3e6a8cedcc8275a04564ca752.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://ik1g19.github.io/UoS-Notes",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://ik1g19.github.io/UoS-Notes",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/ik1g19.github.io\/UoS-Notes\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=ik1g19.github.io/UoS-Notes src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://ik1g19.github.io/UoS-Notes/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://ik1g19.github.io/UoS-Notes/>My UoS Notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Local Interest Points</h1><p class=meta>Last updated
Apr 12, 2023
<a href=https://github.com/ik1g19/notes/Computer%20Vision/Local%20Interest%20Points.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#different-types-of-interest-points-to-choose-from>Different types of interest points to choose from</a><ol><li><a href=#blob-detection---difference-of-gaussian-extrema>Blob Detection - Difference-of-Gaussian Extrema</a></li><li><a href=#corner-detection---harris-and-stephens>Corner Detection - Harris and Stephens</a></li></ol></li></ol><ol><li><a href=#basic-idea>Basic Idea</a></li><li><a href=#flat-region>&ldquo;Flat&rdquo; Region</a></li><li><a href=#edge-region>&ldquo;Edge&rdquo; Region</a></li><li><a href=#corner-region>&ldquo;Corner&rdquo; Region</a></li><li><a href=#mathematics>Mathematics</a><ol><li><a href=#the-structure-tensor>The Structure Tensor</a></li></ol></li></ol><ol><li><a href=#the-problem-of-scale>The Problem of Scale</a></li><li><a href=#scale-space-theory>Scale Space Theory</a><ol><li><a href=#a-formal-framework-for-handling-the-scale-problem>A formal framework for handling the scale problem</a></li></ol></li></ol><ol><li><a href=#gaussian-pyramid>Gaussian Pyramid</a></li></ol><ol><li><a href=#scale-space--log>Scale Space LoG</a></li><li><a href=#scale-space-dog>Scale Space DoG</a></li><li><a href=#dog-pyramid>DoG Pyramid</a></li></ol></nav></details></aside><a href=#what-makes-a-good-interest-point-in-an-image><h1 id=what-makes-a-good-interest-point-in-an-image><span class=hanchor arialabel=Anchor># </span>What makes a good Interest Point in an Image?</h1></a><ul><li>Invariance to brightness change<ul><li>Local changes as well as global ones</li></ul></li><li>Sufficient texture variation in the local neighbourhood</li><li>Invariance to position between the angle/position of the scene to the camera</li></ul><a href=#finding-interest-points><h1 id=finding-interest-points><span class=hanchor arialabel=Anchor># </span>Finding Interest Points</h1></a><a href=#different-types-of-interest-points-to-choose-from><h2 id=different-types-of-interest-points-to-choose-from><span class=hanchor arialabel=Anchor># </span>Different types of interest points to choose from</h2></a><a href=#blob-detection---difference-of-gaussian-extrema><h3 id=blob-detection---difference-of-gaussian-extrema><span class=hanchor arialabel=Anchor># </span>Blob Detection - Difference-of-Gaussian Extrema</h3></a><p><img src=https://remnote-user-data.s3.amazonaws.com/aMdPOOwczOgzvqXqJ4I1I63efazF5aRvMBXds4R27kRVlHarabPZzDCWDfFBj2cm37KGhiacPl139iCPu5JIXEfHSwcwt6aopI6xEq6dEDu_SVmDdOP-yIuoO6rGZr14.png width=200 alt=|200></p><a href=#corner-detection---harris-and-stephens><h3 id=corner-detection---harris-and-stephens><span class=hanchor arialabel=Anchor># </span>Corner Detection - Harris and Stephens</h3></a><p><img src=https://remnote-user-data.s3.amazonaws.com/beEThfWceMkMF6riundQ4w71N5-meJN4o157TdEUV5ogaQA0mtGVBCFhh5VdvSbHCo5qaSn3b7m_iE1jimGzPgzCz2-Hp4Vpfb7-yfGGx7gzvFIl8oUXLaKI_n0_JkSK.png width=200 alt=|200></p><a href=#harris-and-stephens-corner-detector><h1 id=harris-and-stephens-corner-detector><span class=hanchor arialabel=Anchor># </span>Harris and Stephens Corner Detector</h1></a><a href=#basic-idea><h2 id=basic-idea><span class=hanchor arialabel=Anchor># </span>Basic Idea</h2></a><ul><li>Shifting that window by a small amount in any direction should give a large change in intensity</li><li>Search for corners by looking through a small window</li></ul><a href=#flat-region><h2 id=flat-region><span class=hanchor arialabel=Anchor># </span>&ldquo;Flat&rdquo; Region</h2></a><p>No change in all directions
<img src=https://remnote-user-data.s3.amazonaws.com/bmDg-eaIoCTTnbVI8w4POY5E7Jmuc1HXQkpGCAE0dW__19MYQ-Y_3kr1uncBUb3bkiEeq4bk3pPPDidnZDiwvN_SJkluNkncjzYFnD_oFo4dWGre97L8Y8B-Y_MvnfOd.png width=200 alt=|200></p><a href=#edge-region><h2 id=edge-region><span class=hanchor arialabel=Anchor># </span>&ldquo;Edge&rdquo; Region</h2></a><p>No change along the edge direction
<img src=https://remnote-user-data.s3.amazonaws.com/XwRLRFhiUB_69yKDyYpBupG0jurIO1tRLLV4tEvzbC6J3TmAC2-TxX7lfrRYj0w7tcD4qs6ZWbkr0oNfbTCPeLrs4ezVucUuSCd2Wg-eZVmNsKnrx6yn117zu05c1kvr.png width=200 alt=|200></p><a href=#corner-region><h2 id=corner-region><span class=hanchor arialabel=Anchor># </span>&ldquo;Corner&rdquo; Region</h2></a><p>Significant change in all directions
<img src=https://remnote-user-data.s3.amazonaws.com/iAwkm99HKJHOYAlBcMFSoldgDOfPwF_99OfQmqpcoIQHqR9BNnnBgmbUu3S3tUfIRJM3bvaOWYSwdjH8LRcoMnOgYpZ1PTLbynNCtrGki62bkkEma4nrMjxkxWUgfeaW.png width=200 alt=|200></p><a href=#mathematics><h2 id=mathematics><span class=hanchor arialabel=Anchor># </span>Mathematics</h2></a><p>Weighted average change in intensity between a window and a shifted version by $(\Delta x,\Delta y)$ of that window</p><a href=#the-structure-tensor><h3 id=the-structure-tensor><span class=hanchor arialabel=Anchor># </span>The Structure Tensor</h3></a><p><img src=https://remnote-user-data.s3.amazonaws.com/Je6Z478m9wLorS8b1OY40dESQjYfAdoqFGTA1vj-AV3e3jL-g_ng4HJdWl_65kC0_4G9N7ouOg4cPr_ZiMBd5SvYcRfpLNmYBwqfjpSVdc3z0qErPpVuqXrAdutUTxpt.png width=200 alt=|200>
The square symmetric matrix $\textbf{M}$ is called the Structure Tensor or the Second Moment Matrix
$$\textbf{M}=\begin{bmatrix}
\sum_W(I_x(x_i,y_i))^2 & \sum_WI_x(x_i,y_i)I_y(x_i,y_i))\\ \sum_WI_x(x_i,y_i)I_y(x_i,y_i) &
\sum_W(I_y(x_i,y_i))^2
\end{bmatrix}$$</p><ul><li>The eigenvalues and vectors tell us the rates of change and their respective directions</li><li>It concisely encodes how the local shape intensity function of the window changes with small shifts</li><li>As with the 2d covariance matrix, the structure tensor describes an ellipse
<img src=https://remnote-user-data.s3.amazonaws.com/Dt9rM1y7UIgDaWDRXOZvFw0-vTpcPyePBL6YpxeNluy8isGJHUtUN0SRhrX5NPqJXJcd-jPuWhXtaIjMhLL-C7caWTzbMUOZNExKrSer32r19eNXHN19VEy3WcPRzSRi.gif width=400 alt=|400>
The Taylor expansion allows us to approximate the shifted intensity
We can substitute and simplify the previous equation to
$$\begin{bmatrix}
\Delta x & \Delta y\\ \end{bmatrix}
\textbf{M}
\begin{bmatrix}
\Delta x\\ \Delta y\\ \end{bmatrix}</li><li>\begin{bmatrix}
\Delta x & \Delta y\\ \end{bmatrix}
\begin{bmatrix}
\sum_W(I_x(x_i,y_i))^2 & \sum_WI_x(x_i,y_i)I_y(x_i,y_i))\\ \sum_WI_x(x_i,y_i)I_y(x_i,y_i) &
\sum_W(I_y(x_i,y_i))^2
\end{bmatrix}
\begin{bmatrix}
\Delta x\\ \Delta y\\ \end{bmatrix} $$
$$E(x,y)=\sum\limits_Wf(x_i,y_i)[I(x_i,y_i)-I(x_i+\Delta x,y_i+\Delta y)]^2$$
Where</li><li>$I(x_i,y_i)$ - Intensity in window</li><li>$f(x_i,y_i)$ - Weighting function</li><li>$I(x_i+\Delta x,y_i + \Delta y)$ - Intensity in shifted window</li></ul><a href=#harris-and-stephens-response-function><h1 id=harris-and-stephens-response-function><span class=hanchor arialabel=Anchor># </span>Harris and Stephens Response Function</h1></a><p>Rather than compute the eigenvalues directly, Harris and Stephens defined a corner response function in terms of the determinant and trace of $\textbf{M}$
<img src=https://remnote-user-data.s3.amazonaws.com/EeUxo5u5UcFr0kmT9qXROSL63tTyAPGV-S0TvFu9km65cyjzX5475WBTOmXYAGL1unx3ORhFQHVJ0lmyC2Lh-SFdyUQYk4Z9xHJ7QGj7Tk2Iv1E-hJknr6Lb0s4tbh8v.png width=400 alt=|400>
Where</p><ul><li>k - A small empirically set constant (usually 0.04 - 0.06)
<img src=https://remnote-user-data.s3.amazonaws.com/mLQjESv_ysA_GTuTJ51rdS-z39hRn1-mqwBHKJr-XVn4a3hc8dQWw-XmxVsRhDPYgRjd1Lq-LLeWouF_kiYw2VDliWCqQT-_zxp85Tz6jzyJW_KjU89E6la1bF6SX_50.png width=400 alt=|400></li></ul><a href=#harris-and-stephens-detector><h1 id=harris-and-stephens-detector><span class=hanchor arialabel=Anchor># </span>Harris and Stephens Detector</h1></a><ul><li>Take all points with the response value above a threshold</li></ul><ol><li>Keep only the points that are local maxima<ul><li>i.e. Where the current response is bigger than the 8 neighbouring pixels</li></ul></li></ol><a href=#scale-in-computer-vision><h1 id=scale-in-computer-vision><span class=hanchor arialabel=Anchor># </span>Scale in Computer Vision</h1></a><a href=#the-problem-of-scale><h2 id=the-problem-of-scale><span class=hanchor arialabel=Anchor># </span>The Problem of Scale</h2></a><ul><li>If you use a technique that uses a fixed size processing window (e.g. Harris corners) then this causes problems</li><li>As an object gets closer to the camera it gets larger with more detail, as it moves further away it gets smaller and loses detail</li></ul><a href=#scale-space-theory><h2 id=scale-space-theory><span class=hanchor arialabel=Anchor># </span>Scale Space Theory</h2></a><a href=#a-formal-framework-for-handling-the-scale-problem><h3 id=a-formal-framework-for-handling-the-scale-problem><span class=hanchor arialabel=Anchor># </span>A formal framework for handling the scale problem</h3></a><ul><li>Key notion - Image structures smaller than sqrt(t) have been smoothed away at a scale t</li><li>Represent the image by a series of increasingly blurred/smoothed images parameterised by a scale parameter t<ul><li>Where t represents the amount of smoothing</li></ul></li></ul><a href=#gaussian-scale-space><h1 id=gaussian-scale-space><span class=hanchor arialabel=Anchor># </span>Gaussian Scale Space</h1></a><p>Many types of scale space are possible
Only the gaussian function has the desired properties for image representation</p><ul><li>These provable properties are called the &ldquo;scale space axioms&rdquo;</li></ul><p>Gaussian scale space is defined as
<img src=https://remnote-user-data.s3.amazonaws.com/GHenUWytFRU2JFwkYgkxaF_CemFSDlRj9nVGWfXFy359y6Bruf4mNb4IGJglWhBJs3uwaIv2fw3txINTudvcIxJ0QlSApvJ1of5_UvUZ-4F0j8mTU5pr1Axwwqrgq7MU.png width=400 alt=|400>
$$L(\cdot,\cdot,;t)=g(\cdot,\cdot;t)*f(\cdot,\cdot)$$
Where</p><ul><li>$g(\cdot,\cdot;t)*f(\cdot,\cdot)$ - A convolution of the gaussian with parameter t over the image $f(\cdot,\cdot)$</li><li>$L(\cdot,\cdot,;t)$ - A set of images<ul><li>$\cdot,\cdot$ - Spatial coordinates of the image</li><li>t - Scale parameter $(t\geq0)$<ul><li>$t=\sigma^2=\text{variance of the gaussian}$</li></ul></li></ul></li></ul><a href=#nyquist-shannon-sampling-theorem><h1 id=nyquist-shannon-sampling-theorem><span class=hanchor arialabel=Anchor># </span>Nyquist-Shannon Sampling Theorem</h1></a><p>If a function x(t) contains no frequencies higher than B hertz, it is completely determined by giving its ordinates at a series of points spaced $\frac{1}{2B}$ seconds apart
So, if you filter the signal with a low-pass filter that halves the frequency content, you can also half the sampling rate without loss of information</p><a href=#gaussian-pyramid><h2 id=gaussian-pyramid><span class=hanchor arialabel=Anchor># </span>Gaussian Pyramid</h2></a><p>Every time you double t in scale space, you can half the image size without loss of information
<img src=https://remnote-user-data.s3.amazonaws.com/ODRxuLwXv4lScvGNPzZ_Hj0CdgJV3e7aR1uoHdL3OxWOG-nd_q0BTxHLYCaimi6PNFzC3KgKzwAuG2ShT_UarYhUvmujmsOjMStOnDyiln9LXXHqFPgNsSYhusgoJgYV.png width=400 alt=|400>
Leads to a much more efficient representation</p><ul><li>Less memory</li><li>Faster processing</li></ul><a href=#multi-scale-harris-and-stephens><h1 id=multi-scale-harris-and-stephens><span class=hanchor arialabel=Anchor># </span>Multi-Scale Harris and Stephens</h1></a><p>We define a gaussian scale space with a fixed set of scales and computer the corner response function at every pixel of each scale and keep only those with a response above a certain threshold</p><a href=#blob-detection><h1 id=blob-detection><span class=hanchor arialabel=Anchor># </span>Blob Detection</h1></a><p>Laplacian of Gaussian LoG is the second derivative of a gaussian
By finding the local minima or maxima after convolving a LoG, you get a blob detector</p><a href=#scale-space--log><h2 id=scale-space--log><span class=hanchor arialabel=Anchor># </span>Scale Space LoG</h2></a><p>By finding extrema of this function in scale space, you can find blobs at their respective scale (~sqrt(2t))</p><ul><li>Just need to look at the neighbouring pixels</li></ul><p>Useful property</p><ul><li>If a blob is detected at $(x_0,y_0;t_0)$ in an image, then under a scaling of that image by a factor s, the same blob would be detected at $(sx_0,sy_0;s^2t_0)$ in the scaled image</li></ul><p>Normalised scale space LoG is defined as
<img src=https://remnote-user-data.s3.amazonaws.com/v3_U8z6HjKA6SOQqD4Ojmg1j0WKGCs68SIYjtXxgQqTbSUNDaUgVqstw1vq8YXvcygidEXLdVQYIdpLzplusdVV86tS6alXCLxXPmeY3crZEcDOTbd5dyR9jgppV_sXD.png width=400 alt=|400></p><a href=#scale-space-dog><h2 id=scale-space-dog><span class=hanchor arialabel=Anchor># </span>Scale Space DoG</h2></a><p>In practice its computationally expensive to build a LoG scale space
But you can make the approximation
<img src=https://remnote-user-data.s3.amazonaws.com/EoOil7XsYINvpDlyB1m94xLhtTmM2-m4ANAtfnVa3NR0i-gRzn-jJ4vuDHkUkeKkxdBnMs2kYrDuqpLNTvkFkOnKs4fk_lZoNFHRcZZptkaVoZReGx0K_NzShpesJfT9.png width=400 alt=|400></p><p>This is called a Difference-of-Gaussians (DoG)</p><ul><li>Implies that the LoG scale space can be built from subtracting adjacent scales of a Gaussian scale space</li></ul><a href=#dog-pyramid><h2 id=dog-pyramid><span class=hanchor arialabel=Anchor># </span>DoG Pyramid</h2></a><p>For efficiency you can build a DoG pyramid</p><ul><li>Images between a doubling of scale are an octave
<img src=https://remnote-user-data.s3.amazonaws.com/V3paxVIVgQRuMsYQX2cE-V1xpBwDcEwUwuA7j8CsPGL5Ws9uxIMz5QOUhOxixPwS3RPDzAO5QP3mv5JIkcTx8sxgw2MQPKG3o6m4pVGc0ALnRzDXjspnopyo4ORDj1E9.png width=400 alt=|400>
An oversampled pyramid as there are multiple images between a doubling of scale</li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://ik1g19.github.io/UoS-Notes/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Isaac Klugman using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://ik1g19.github.io/UoS-Notes/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>GitHub</a></li></ul></footer></div></div></body></html>